# generated by patch-package 6.4.14
#
# declared package:
#   kafkajs: 2.2.4
#
diff --git a/node_modules/kafkajs/src/network/connection.js b/node_modules/kafkajs/src/network/connection.js
index dded584..50492b4 100644
--- a/node_modules/kafkajs/src/network/connection.js
+++ b/node_modules/kafkajs/src/network/connection.js
@@ -393,7 +393,7 @@ module.exports = class Connection {
       this.logDebug(`Request ${requestInfo(request)}`, {
         correlationId,
         expectResponse,
-        size: Buffer.byteLength(requestPayload.buffer),
+        size: Buffer.byteLength(requestPayload.view()),
       })
 
       return new Promise((resolve, reject) => {
@@ -406,7 +406,7 @@ module.exports = class Connection {
             expectResponse,
             requestTimeout,
             sendRequest: () => {
-              this.socket.write(requestPayload.buffer, 'binary')
+              this.socket.write(requestPayload.view(), 'binary')
             },
           })
         } catch (e) {
diff --git a/node_modules/kafkajs/src/protocol/decoder.js b/node_modules/kafkajs/src/protocol/decoder.js
index e2834d0..fcabd2f 100644
--- a/node_modules/kafkajs/src/protocol/decoder.js
+++ b/node_modules/kafkajs/src/protocol/decoder.js
@@ -90,8 +90,7 @@ module.exports = class Decoder {
       return null
     }
 
-    const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength)
-    const value = stringBuffer.toString('utf8')
+    const value = this.buffer.toString('utf8', this.offset, this.offset + byteLength)
     this.offset += byteLength
     return value
   }
@@ -103,8 +102,7 @@ module.exports = class Decoder {
       return null
     }
 
-    const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength)
-    const value = stringBuffer.toString('utf8')
+    const value = this.buffer.toString('utf8', this.offset, this.offset + byteLength)
     this.offset += byteLength
     return value
   }
@@ -116,9 +114,7 @@ module.exports = class Decoder {
       return null
     }
 
-    const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength - 1)
-    const value = stringBuffer.toString('utf8')
-
+    const value = this.buffer.toString('utf8', this.offset, this.offset + byteLength - 1)
     this.offset += byteLength - 1
     return value
   }
@@ -132,9 +128,9 @@ module.exports = class Decoder {
       return null
     }
 
-    const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength)
+    const stringSubarray = this.buffer.subarray(this.offset, this.offset + byteLength)
     this.offset += byteLength
-    return stringBuffer
+    return stringSubarray
   }
 
   readVarIntBytes() {
@@ -144,9 +140,9 @@ module.exports = class Decoder {
       return null
     }
 
-    const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength)
+    const bytesSubarray = this.buffer.subarray(this.offset, this.offset + byteLength)
     this.offset += byteLength
-    return stringBuffer
+    return bytesSubarray
   }
 
   readUVarIntBytes() {
@@ -156,9 +152,9 @@ module.exports = class Decoder {
       return null
     }
 
-    const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength)
+    const bytesSubarray = this.buffer.subarray(this.offset, this.offset + byteLength)
     this.offset += byteLength - 1
-    return stringBuffer
+    return bytesSubarray
   }
 
   readBoolean() {
@@ -166,7 +162,7 @@ module.exports = class Decoder {
   }
 
   readAll() {
-    const result = this.buffer.slice(this.offset)
+    const result = this.buffer.subarray(this.offset)
     this.offset += Buffer.byteLength(this.buffer)
     return result
   }
@@ -300,7 +296,7 @@ module.exports = class Decoder {
   }
 
   slice(size) {
-    return new Decoder(this.buffer.slice(this.offset, this.offset + size))
+    return new Decoder(this.buffer.subarray(this.offset, this.offset + size))
   }
 
   forward(size) {
diff --git a/node_modules/kafkajs/src/protocol/encoder.js b/node_modules/kafkajs/src/protocol/encoder.js
index 290bb97..cb381a9 100644
--- a/node_modules/kafkajs/src/protocol/encoder.js
+++ b/node_modules/kafkajs/src/protocol/encoder.js
@@ -92,6 +92,10 @@ module.exports = class Encoder {
     return this.buf.slice(0, this.offset)
   }
 
+  view() {
+    return this.buf.subarray(0, this.offset)
+  }
+
   writeInt8(value) {
     this.ensureAvailable(INT8_SIZE)
     this.buf.writeInt8(value, this.offset)
@@ -400,6 +404,6 @@ module.exports = class Encoder {
   }
 
   toJSON() {
-    return this.buffer.toJSON()
+    return this.view().toJSON()
   }
 }
diff --git a/node_modules/kafkajs/src/protocol/recordBatch/header/v0/decoder.js b/node_modules/kafkajs/src/protocol/recordBatch/header/v0/decoder.js
index a1f56d5..076bef8 100644
--- a/node_modules/kafkajs/src/protocol/recordBatch/header/v0/decoder.js
+++ b/node_modules/kafkajs/src/protocol/recordBatch/header/v0/decoder.js
@@ -1,4 +1,8 @@
-module.exports = decoder => ({
-  key: decoder.readVarIntString(),
-  value: decoder.readVarIntBytes(),
-})
+function decoder(decoder) {
+  const value = Object.create(null)
+  value.key = decoder.readVarIntString()
+  value.value = decoder.readVarIntBytes()
+  return value
+}
+
+module.exports = decoder
\ No newline at end of file
diff --git a/node_modules/kafkajs/src/protocol/recordBatch/record/v0/decoder.js b/node_modules/kafkajs/src/protocol/recordBatch/record/v0/decoder.js
index 641fdd2..c0b9d91 100644
--- a/node_modules/kafkajs/src/protocol/recordBatch/record/v0/decoder.js
+++ b/node_modules/kafkajs/src/protocol/recordBatch/record/v0/decoder.js
@@ -32,8 +32,8 @@ module.exports = (decoder, batchContext = {}) => {
     timestampType === TimestampTypes.LOG_APPEND_TIME && maxTimestamp
       ? maxTimestamp
       : Long.fromValue(firstTimestamp)
-          .add(timestampDelta)
-          .toString()
+        .add(timestampDelta)
+        .toString()
 
   const offsetDelta = decoder.readVarInt()
   const offset = Long.fromValue(firstOffset)
@@ -42,18 +42,17 @@ module.exports = (decoder, batchContext = {}) => {
 
   const key = decoder.readVarIntBytes()
   const value = decoder.readVarIntBytes()
-  const headers = decoder.readVarIntArray(HeaderDecoder).reduce(
-    (obj, { key, value }) => ({
-      ...obj,
-      [key]:
-        obj[key] === undefined
-          ? value
-          : Array.isArray(obj[key])
-          ? obj[key].concat([value])
-          : [obj[key], value],
-    }),
-    {}
-  )
+  const headers = decoder.readVarIntArray(HeaderDecoder).reduce((obj, { key, value }) => {
+    const existing = obj[key];
+    if (existing === undefined) {
+      obj[key] = value;
+    } else if (Array.isArray(existing)) {
+      existing.push(value);
+    } else {
+      obj[key] = [existing, value];
+    }
+    return obj;
+  }, Object.create(null));
 
   return {
     magicByte,
diff --git a/node_modules/kafkajs/src/protocol/recordBatch/v0/decoder.js b/node_modules/kafkajs/src/protocol/recordBatch/v0/decoder.js
index 1d3e204..4eea133 100644
--- a/node_modules/kafkajs/src/protocol/recordBatch/v0/decoder.js
+++ b/node_modules/kafkajs/src/protocol/recordBatch/v0/decoder.js
@@ -26,6 +26,19 @@ const CONTROL_FLAG_MASK = 0x20
  *  Records => [Record]
  */
 
+const codecCache = new Map();
+
+function getCodec(attributes) {
+  const cachedCodec = codecCache.get(attributes)
+  // if the codec is null, look it up and cache it and return it
+  if (cachedCodec !== undefined) {
+    return cachedCodec
+  }
+  const codec = lookupCodecByAttributes(attributes)
+  codecCache.set(attributes, codec)
+  return codec
+};
+
 module.exports = async fetchDecoder => {
   const firstOffset = fetchDecoder.readInt64().toString()
   const length = fetchDecoder.readInt32()
@@ -65,28 +78,22 @@ module.exports = async fetchDecoder => {
       ? TimestampTypes.LOG_APPEND_TIME
       : TimestampTypes.CREATE_TIME
 
-  const codec = lookupCodecByAttributes(attributes)
-
-  const recordContext = {
-    firstOffset,
-    firstTimestamp,
-    partitionLeaderEpoch,
-    inTransaction,
-    isControlBatch,
-    lastOffsetDelta,
-    producerId,
-    producerEpoch,
-    firstSequence,
-    maxTimestamp,
-    timestampType,
-  }
-
-  const records = await decodeRecords(codec, decoder, { ...recordContext, magicByte })
-
-  return {
-    ...recordContext,
-    records,
-  }
+  var recordContext = Object.create(null)
+  recordContext.firstOffset = firstOffset
+  recordContext.firstTimestamp = firstTimestamp
+  recordContext.partitionLeaderEpoch = partitionLeaderEpoch
+  recordContext.inTransaction = inTransaction
+  recordContext.isControlBatch = isControlBatch
+  recordContext.lastOffsetDelta = lastOffsetDelta
+  recordContext.producerId = producerId
+  recordContext.producerEpoch = producerEpoch
+  recordContext.firstSequence = firstSequence
+  recordContext.maxTimestamp = maxTimestamp
+  recordContext.timestampType = timestampType
+  recordContext.magicByte = magicByte
+  recordContext.records = await decodeRecords(getCodec(attributes), decoder, recordContext)
+
+  return recordContext
 }
 
 const decodeRecords = async (codec, recordsDecoder, recordContext) => {
diff --git a/node_modules/kafkajs/src/protocol/recordBatch/v0/index.js b/node_modules/kafkajs/src/protocol/recordBatch/v0/index.js
index 599a940..4d754a9 100644
--- a/node_modules/kafkajs/src/protocol/recordBatch/v0/index.js
+++ b/node_modules/kafkajs/src/protocol/recordBatch/v0/index.js
@@ -72,10 +72,10 @@ const RecordBatch = async ({
   const batch = new Encoder()
     .writeInt32(partitionLeaderEpoch)
     .writeInt8(MAGIC_BYTE)
-    .writeUInt32(crc32C(batchBody.buffer))
+    .writeUInt32(crc32C(batchBody.view()))
     .writeEncoder(batchBody)
 
-  return new Encoder().writeInt64(firstOffset).writeBytes(batch.buffer)
+  return new Encoder().writeInt64(firstOffset).writeBytes(batch.view())
 }
 
 const compressRecords = async (compression, records) => {
diff --git a/node_modules/kafkajs/src/protocol/requests/fetch/v4/decodeMessages.js b/node_modules/kafkajs/src/protocol/requests/fetch/v4/decodeMessages.js
index abae0f5..58e9008 100644
--- a/node_modules/kafkajs/src/protocol/requests/fetch/v4/decodeMessages.js
+++ b/node_modules/kafkajs/src/protocol/requests/fetch/v4/decodeMessages.js
@@ -17,7 +17,7 @@ const decodeMessages = async decoder => {
 
   const messagesBuffer = decoder.readBytes(messagesSize)
   const messagesDecoder = new Decoder(messagesBuffer)
-  const magicByte = messagesBuffer.slice(MAGIC_OFFSET).readInt8(0)
+  const magicByte = messagesBuffer.subarray(MAGIC_OFFSET).readInt8(0)
 
   if (magicByte === MAGIC_BYTE) {
     const records = []
